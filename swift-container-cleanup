#!/usr/bin/env python
# Copyright (c) 2010-2012 OpenStack Foundation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import print_function
import os
import sys
import getopt
import itertools
import json
import time
import subprocess
from datetime import datetime

from eventlet.greenpool import GreenPool
from eventlet import Timeout
from six.moves.urllib.parse import quote, unquote
from swift.common.ring import Ring
from swift.common.utils import split_path, Timestamp
from swift.common import direct_client
from swift.common.exceptions import ClientException


C_TIMEOUT = 10
R_TIMEOUT = 30
STATS_INTERVAL = 300
last_modified_dict = {}
last_modified_dict_pot_miss = {}

usage = """%(cmd)s [options] [path 1] [path 2] ...
    -c [concurrency]      Set the concurrency, default 50
    -r [ring dir]         Ring locations, default /etc/swift
    -e [filename]         File for writing a list of missing objects
    -d                    Delete object row from container listing that can't
                          be retrieved.
    -p                    When auditing an object check all devices in cluster
                          instead of num-replicas * 2 (num-primaries + num-handoffs)
                          num-replicas * 2 is default. An unresponsive server
                          that is not a primary/handoff will not prevent a
                          delete.
    -t                    Query every container node. (#container replicas slower)
    -m                    Ignore any objects with last_modified < 'm' seconds ago
    -v                    verbose (will print out objects it finds)
    -f                    ssh out to call direct replication on completely out of place partitions

This finds and optionally removes container entries with no backing objects.
The paths need to be URL-encoded.
You can also feed a list of paths via stdin.
Output can be quite chatty, especially if you have nodes down or something.
You may want to tee it to a file for later review.

This will scan a container and put any missing objects in a text file.
    %(cmd)s -e missing.txt 'AUTH_test/container'

This will check all of the objects in a text file and delete them if it can't
find them.
    %(cmd)s -d < errors.txt

You can scan an account, container, or object:
    %(cmd)s 'AUTH_test'
    %(cmd)s 'AUTH_test/container'
    %(cmd)s 'AUTH_test/container/object'

Paths should be already encoded.
    %(cmd)s 'AUTH_test/container/object%%20with%%20spaces'
""" % {'cmd': os.path.basename(sys.argv[0])}


def _print_stat(name, stat):
    # Right align stat name in a field of 18 characters
    print("{0:>30}: {1}".format(name, stat))


def deunicode_node(node):
    for k, v in node.iteritems():
        if isinstance(v, unicode):
            node[k] = v.encode('utf-8')

class Auditor(object):
    def __init__(self, swift_dir='/etc/swift', concurrency=50, delete=False,
                 error_file=None, check_all=False, check_all_containers=False,
                 min_age=0, verbose=False, ssh_rescue=False):
        # dedicate 25% of concurrency to containers and 75% to objects.
        # this is ugly, but it's a simple concurrency model.
        self.container_pool = GreenPool(max(1, int(concurrency / 4)))
        self.object_pool = GreenPool(max(1, int((concurrency / 4.0) * 3.0)))
        self.delete = delete
        self.check_all = check_all
        self.check_all_containers = check_all_containers
        self.object_ring = Ring(swift_dir, ring_name='object')
        self.container_ring = Ring(swift_dir, ring_name='container')
        self.account_ring = Ring(swift_dir, ring_name='account')
        self.start_time = time.time()
        self.last_stat = time.time()
        self.account_objs = 0
        self.min_age = min_age
        self.verbose = verbose
        self.ssh_rescue = ssh_rescue
        self.parts_to_rescue = set([])
        self.devices_rescuing = {}
        self.rescue_processes = []
        if error_file is not None:
            self.error_file = open(error_file, 'a')
        else:
            self.error_file = None
        # zero out stats
        self.accounts_checked = self.containers_checked = \
            self.objects_checked = self.missing_objects = \
            self.potentially_missing = self.accounts_failed = \
            self.containers_failed = self.objects_deleted = \
            self.account_objects_checked = 0


    def delete_from_container(self, account, container, obj):
        success = True
        part, nodes = self.container_ring.get_nodes(account, container)
        headers = {"X-Timestamp": Timestamp(time.time()).internal}
        for node in nodes:
            deunicode_node(node)
            try:
                direct_client.direct_delete_container_object(
                    node, part, account, container, obj, headers=headers,
                    conn_timeout=C_TIMEOUT, response_timeout=R_TIMEOUT)
            except (Exception, Timeout) as err:
                print('Exception deleting object from container:', err)
                success = False
        return success

    def rescue_part_ssh(self, ip, device, part):
        if part in self.parts_to_rescue:
            return
        if len(self.parts_to_rescue) > 50:
            print("too many rescueparts running. cannot fix %s" % part)
            return
        ipd = "%s/%s" % (ip, device)
        self.devices_rescuing[ipd] = self.devices_rescuing.get(ipd,0) + 1
        if self.devices_rescuing[ipd] > 1:
            print("will not send more than 1 replication call to a single device")
            return

        self.parts_to_rescue.add(part)
        cmd = 'ssh -o "StrictHostKeyChecking no" %s "hummingbird object-replicator -partitions %s -devices %s -once"' % (ip, part, device)
        print("spawning %s" % cmd)

        p = subprocess.Popen(cmd, shell=True)
        self.rescue_processes.append(p)

    def rescue_part(self, part):
        if part in self.parts_to_rescue:
            return
        if len(self.parts_to_rescue) > 50:
            print("too many rescueparts running. cannot fix %s" % part)
            return
        self.parts_to_rescue.add(part)
        cmd = ['hummingbird', 'rescueparts', str(part)]
        print("spawning %s" % " ".join(cmd))
        p = subprocess.Popen(cmd)
        self.rescue_processes.append(p)

    def wait_for_rescues(self):
        for p in self.rescue_processes:
            p.wait()

    def audit_object(self, account, container, obj, last_mod='', list_time=''):
        if time.time() - self.last_stat > STATS_INTERVAL:
            self.print_stats()
            self.last_stat = time.time()
        path = '/%s/%s/%s' % (quote(account), quote(container), quote(obj))
        part, nodes = self.object_ring.get_nodes(account, container, obj)
        num_ph_nodes = len(nodes) * 2
        num_nodes = num_ph_nodes
        if self.check_all:
            num_nodes = len(self.object_ring.devs)
        node_iter = itertools.islice(
            itertools.chain(nodes, self.object_ring.get_more_nodes(part)),
            num_nodes)
        found_replicas = 0
        exception_count = 0
        i = 0

        head_time = time.strftime("%Y-%m-%dT%H:%M:%S")
        for node in node_iter:
            deunicode_node(node)
            try:
                direct_client.direct_head_object(node, part, account,
                    container, obj,
                    conn_timeout=C_TIMEOUT, response_timeout=R_TIMEOUT,
                    headers={"X-Force-Acquire": "true"})
                found_replicas += 1
                if i >= num_ph_nodes:
                    if self.ssh_rescue:
                        self.rescue_part_ssh(node['ip'], node['device'], part)
                    else:
                        self.rescue_part(part)
                if self.verbose:
                    print("DEBUG: found object %s on node %s:%s/%s" % (
                        path, node['ip'], node['port'], node['device']))
                break
            except direct_client.DirectClientException as err:
                if not(err.http_status == 404 or err.http_status == 507):
                    # treating unmounted drives (507s) as dead. all objs gone
                    if i >= num_ph_nodes:
                        continue # error only when node is primary or handoff
                    exception_count += 1
                    print('Unacceptable status code %s from "%s" on %s:%s/%s'
                          % (err.http_status, path, node['ip'], node['port'],
                             node['device']))
            except (Exception, Timeout) as err:
                if i >= num_ph_nodes:
                    continue # error only when node is primary or handoff
                exception_count += 1
                print('Exception fetching object "%s" on %s:%s/%s : %s'
                      % (path, node['ip'], node['port'], node['device'], err))
            i += 1
        still_in_listings = False # check if obj deleted from under us
        if found_replicas == 0:
            part, nodes = self.container_ring.get_nodes(account, container)
            if list_time == '':
                list_time = time.strftime("%Y-%m-%dT%H:%M:%S")
            for node in nodes:
                deunicode_node(node)
                try:
                    _, cresults = direct_client.direct_get_container(
                        node, part, account, container, prefix=obj, limit=1,
                        conn_timeout=C_TIMEOUT, response_timeout=R_TIMEOUT)
                except (Exception, Timeout) as err:
                    print('Exception double check cont "%s" on %s:%s/%s : %s'
                          % (path, node['ip'], node['port'], node['device'], err))
                    continue
                else:
                    if cresults:
                        for cobj in cresults:
                            if cobj['name'] == obj:
                                still_in_listings = True
                                last_mod = cobj['last_modified']
                                break
            if last_mod == '':
                last_mod = 'not-in-listing'

        if found_replicas == 0 and exception_count == 0 and still_in_listings:
            self.missing_objects += 1
            print('Missing object: %s last-mod: %s listing: %s audit: %s' % (
                path, last_mod, list_time, head_time))
            last_mod_day = last_mod[:10]
            last_modified_dict[last_mod_day] = last_modified_dict.get(last_mod_day, 0) + 1
            if self.error_file is not None:
                print(path, file=self.error_file)
                self.error_file.flush()
            if self.delete:
                print('  ...Deleting %s' % path)
                if self.delete_from_container(account, container, obj):
                    self.objects_deleted += 1
                else:
                    print('  ...Delete failed %s' % path)
        elif found_replicas == 0 and exception_count > 0 and still_in_listings:
            print("ATTENTION: marking %s as potentially missing" % path)
            if last_mod:
                last_mod_day = last_mod[:10]
                last_modified_dict_pot_miss[last_mod_day] = \
                    last_modified_dict_pot_miss.get(last_mod_day, 0) + 1
            self.potentially_missing += 1
        self.objects_checked += 1
        self.account_objects_checked += 1

    def audit_container(self, account, container):
        print('Auditing container "%s"' % container)
        path = '/%s/%s' % (quote(account), quote(container))
        part, nodes = self.container_ring.get_nodes(account, container)
        for node in nodes:
            deunicode_node(node)
            marker = ''
            results = True
            while results:
                try:
                    list_time = time.strftime("%Y-%m-%dT%H:%M:%S")
                    _, results = direct_client.direct_get_container(
                        node, part, account, container, marker=marker,
                        conn_timeout=C_TIMEOUT, response_timeout=R_TIMEOUT)
                    if results:
                        marker = results[-1]['name'].encode('utf-8')
                        for obj in results:
                            last_mod = datetime.strptime(
                                obj['last_modified'], "%Y-%m-%dT%H:%M:%S.%f")
                            if (self.min_age and
                                    (datetime.now() - last_mod).total_seconds()
                                     < self.min_age):
                                continue
                            self.object_pool.spawn_n(
                                self.audit_object, account, container,
                                obj['name'].encode('utf-8'),
                                obj['last_modified'], list_time)
                    else:
                        self.containers_checked += 1
                        if self.check_all_containers:
                            print("Completed container: %s at %s:%d" %(path, node['ip'], node['port']))
                            break
                        else:
                            print("Completed container:", path)
                            return
                except (Exception, Timeout) as err:
                    print('  Exception GETting container "%s" on %s/%s : %s' %
                          (path, node['ip'], node['device'], err))
                    break
        else:
            return
        self.containers_failed += 1
        print("Failed to list container:", path)

    def audit_account(self, account):
        print('Auditing account "%s"' % account)
        part, nodes = self.account_ring.get_nodes(account)
        path = '/%s' % quote(account)
        for node in nodes:
            deunicode_node(node)
            marker = ''
            results = True
            while results:
                node_id = node['id']
                try:
                    hdrs, results = direct_client.direct_get_account(
                        node, part, account, marker=marker,
                        conn_timeout=C_TIMEOUT, response_timeout=R_TIMEOUT)
                    if results:
                        if marker == '':
                            self.current_account = account
                            self.account_objs = int(hdrs.get(
                                "X-Account-Object-Count", 0))
                            self.account_objects_checked = 0
                        marker = results[-1]['name'].encode('utf-8')
                        for container in results:
                            self.container_pool.spawn_n(
                                self.audit_container, account,
                                container['name'].encode('utf-8'))
                    else:
                        self.accounts_checked += 1
                        print("Completed account:", path)
                        self.wait()
                        self.print_stats()
                        return
                except (Exception, Timeout) as err:
                    print("  Exception GETting account '%s' on %s:%s : %s" %
                          (account, node['ip'], node['device'], err))
                    break
        self.accounts_failed += 1
        print("Failed to list account:", path)

    def audit(self, account, container=None, obj=None):
        if obj and container:
            self.object_pool.spawn_n(self.audit_object, account, container, obj)
        elif container:
            self.container_pool.spawn_n(self.audit_container, account, container)
        elif account:
            self.audit_account(account)

    def wait(self):
        self.container_pool.waitall()
        self.object_pool.waitall()

    def print_stats(self):
        if self.account_objs > 0:

            print()
            _print_stat('Audit stats for', self.current_account)
            _print_stat("# Objects in Account", self.account_objs)
            obj_sec = self.account_objects_checked / (time.time() - self.start_time)
            _print_stat("Object Checks/sec", "%.2f" % obj_sec)
            obj_left = self.account_objs - self.account_objects_checked
            _print_stat("Objects left", obj_left)
            _print_stat("Estimated time left",
                        "%.1f secs" % (obj_left / obj_sec))

        print()
        _print_stat("Accounts Checked", self.accounts_checked)
        _print_stat("Failed To List", self.accounts_failed)
        print()
        _print_stat("Containers checked", self.containers_checked)
        _print_stat("Failed To List", self.containers_failed)
        print()
        _print_stat("Objects Checked", self.objects_checked)
        _print_stat("Missing Objects", self.missing_objects)
        _print_stat("Deleted From Containers", self.objects_deleted)
        if self.potentially_missing:
            _print_stat("Potentially Missing Objects", self.potentially_missing)
            print()
            print("'Potentially Missing' means we couldn't find the object,")
            print("but a node timed out or was unmounted or something while")
            print("checking, so we won't remove it out of caution.")
        print()
        _print_stat("Have been running for",
                    "%.1f secs" % (time.time() - self.start_time))
        print()
        print("Last Modified Date -> # Missing json:")
        print(json.dumps(last_modified_dict))
        print("Last Modified Date -> # Potentially Missing json:")
        print(json.dumps(last_modified_dict_pot_miss))
        last_mod_days = last_modified_dict.keys()
        last_mod_days.sort()
        if last_mod_days:
            print("Latest Missing last modified date: %s" % last_mod_days[-1])
        plast_mod_days = last_modified_dict_pot_miss.keys()
        plast_mod_days.sort()
        if plast_mod_days:
            print("Latest Potentially Missing last modified date: %s" % plast_mod_days[-1])



if __name__ == '__main__':
    try:
        optlist, args = getopt.getopt(sys.argv[1:], 'a:b:c:r:e:m:i:dptvf')
    except getopt.GetoptError as err:
        print(str(err))
        print(usage)
        sys.exit(2)
    opts = dict(optlist)
    if not args and os.isatty(sys.stdin.fileno()) and not opts.get('-i'):
        print(usage)
        sys.exit()
    options = {
        'concurrency': int(opts.get('-c', 50)),
        'error_file': opts.get('-e', None),
        'swift_dir': opts.get('-r', '/etc/swift'),
        'delete': '-d' in opts,
        'check_all': '-p' in opts,
        'check_all_containers': '-t' in opts,
        'min_age': int(opts.get('-m', 0)),
        'verbose': '-v' in opts,
        'ssh_rescue': '-f' in opts,
    }
    auditor = Auditor(**options)
    if opts.get("-i"):
        with open(opts['-i']) as fi:
            for line in fi:
                try:
                    path = line.strip().lstrip('/')
                    if not path:
                        continue
                    parr = split_path("/" + unquote(path), 1, 3, True)
                except ValueError as e:
                    print("invalid line: %s" % e)
                else:
                    auditor.audit(*parr)

    else:
        if not os.isatty(sys.stdin.fileno()):
            args = itertools.chain(args, sys.stdin)
        for path in args:
            path = '/' + path.rstrip('\r\n').lstrip('/')
            auditor.audit(*split_path(unquote(path), 1, 3, True))
    auditor.wait()
    auditor.print_stats()

    print("waiting on %s rescueparts jobs" % len(auditor.parts_to_rescue))
    if len(auditor.parts_to_rescue) > 50:
        print("had to give up on rescuing some parts because there were so many (> 50)")
        print("you should run this against same input to clean up the rest when it completes")
    for k,v in auditor.devices_rescuing.iteritems():
        if v > 1:
            print("refused to send more than 1 replication command (%s) to %s." % (v, k))
            print("please rerun script with same input when finished")

    auditor.wait_for_rescues()
